{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab:  Logistic Regression for Gene Expression Data\n",
    "\n",
    "In this lab, we use logistic regression to predict biological characteristics (\"phenotypes\") from gene expression data.  In addition to the concepts in [breast cancer demo](./demo04_breast_cancer.ipynb), you will learn to:\n",
    "* Handle missing data\n",
    "* Perform binary classification, and evaluating performance using various metrics\n",
    "* Perform multi-class logistic classification, and evaluating performance using accuracy and confusion matrix\n",
    "* Use L1-regularization to promote sparse weights for improved estimation (Grad students only)\n",
    "\n",
    "## Background\n",
    "\n",
    "Genes are the basic unit in the DNA and encode blueprints for proteins.  When proteins are synthesized from a gene, the gene is said to \"express\".  Micro-arrays are devices that measure the expression levels of large numbers of genes in parallel.  By finding correlations between expression levels and phenotypes, scientists can identify possible genetic markers for biological characteristics.\n",
    "\n",
    "The data in this lab comes from:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression\n",
    "\n",
    "In this data, mice were characterized by three properties:\n",
    "* Whether they had down's syndrome (trisomy) or not\n",
    "* Whether they were stimulated to learn or not\n",
    "* Whether they had a drug memantine or a saline control solution.\n",
    "\n",
    "With these three choices, there are 8 possible classes for each mouse.  For each mouse, the expression levels were measured across 77 genes.  We will see if the characteristics can be predicted from the gene expression levels.  This classification could reveal which genes are potentially involved in Down's syndrome and if drugs and learning have any noticeable effects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We begin by loading the standard modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model, preprocessing, model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `pd.read_excel` command to read the data from \n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls\n",
    "\n",
    "into a dataframe `df`.  Use the `index_col` option to specify that column 0 is the index.  Use the `df.head()` to print the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "df = pd.read_excel(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYRK1A_N</th>\n",
       "      <th>ITSN1_N</th>\n",
       "      <th>BDNF_N</th>\n",
       "      <th>NR1_N</th>\n",
       "      <th>NR2A_N</th>\n",
       "      <th>pAKT_N</th>\n",
       "      <th>pBRAF_N</th>\n",
       "      <th>pCAMKII_N</th>\n",
       "      <th>pCREB_N</th>\n",
       "      <th>pELK_N</th>\n",
       "      <th>...</th>\n",
       "      <th>pCFOS_N</th>\n",
       "      <th>SYP_N</th>\n",
       "      <th>H3AcK18_N</th>\n",
       "      <th>EGR1_N</th>\n",
       "      <th>H3MeK4_N</th>\n",
       "      <th>CaNA_N</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MouseID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>309_1</td>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.747193</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>2.816329</td>\n",
       "      <td>5.990152</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>0.177565</td>\n",
       "      <td>2.373744</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>1.750936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108336</td>\n",
       "      <td>0.427099</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>0.131790</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>1.675652</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309_2</td>\n",
       "      <td>0.514617</td>\n",
       "      <td>0.689064</td>\n",
       "      <td>0.411770</td>\n",
       "      <td>2.789514</td>\n",
       "      <td>5.685038</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.172817</td>\n",
       "      <td>2.292150</td>\n",
       "      <td>0.226972</td>\n",
       "      <td>1.596377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.441581</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>1.743610</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309_3</td>\n",
       "      <td>0.509183</td>\n",
       "      <td>0.730247</td>\n",
       "      <td>0.418309</td>\n",
       "      <td>2.687201</td>\n",
       "      <td>5.622059</td>\n",
       "      <td>0.209011</td>\n",
       "      <td>0.175722</td>\n",
       "      <td>2.283337</td>\n",
       "      <td>0.230247</td>\n",
       "      <td>1.561316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106219</td>\n",
       "      <td>0.435777</td>\n",
       "      <td>0.111883</td>\n",
       "      <td>0.133362</td>\n",
       "      <td>0.127431</td>\n",
       "      <td>1.926427</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N   pBRAF_N  \\\n",
       "MouseID                                                                         \n",
       "309_1    0.503644  0.747193  0.430175  2.816329  5.990152  0.218830  0.177565   \n",
       "309_2    0.514617  0.689064  0.411770  2.789514  5.685038  0.211636  0.172817   \n",
       "309_3    0.509183  0.730247  0.418309  2.687201  5.622059  0.209011  0.175722   \n",
       "\n",
       "         pCAMKII_N   pCREB_N    pELK_N  ...   pCFOS_N     SYP_N  H3AcK18_N  \\\n",
       "MouseID                                 ...                                  \n",
       "309_1     2.373744  0.232224  1.750936  ...  0.108336  0.427099   0.114783   \n",
       "309_2     2.292150  0.226972  1.596377  ...  0.104315  0.441581   0.111974   \n",
       "309_3     2.283337  0.230247  1.561316  ...  0.106219  0.435777   0.111883   \n",
       "\n",
       "           EGR1_N  H3MeK4_N    CaNA_N  Genotype  Treatment  Behavior   class  \n",
       "MouseID                                                                       \n",
       "309_1    0.131790  0.128186  1.675652   Control  Memantine       C/S  c-CS-m  \n",
       "309_2    0.135103  0.131119  1.743610   Control  Memantine       C/S  c-CS-m  \n",
       "309_3    0.133362  0.127431  1.926427   Control  Memantine       C/S  c-CS-m  \n",
       "\n",
       "[3 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has missing values.  The site:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
    "\n",
    "has an excellent summary of methods to deal with missing values.  Following the techniques there, create a new data frame `df1` where the missing values in each column are filled with the mean values from the non-missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DYRK1A_N     0.425810\n",
      "ITSN1_N      0.617102\n",
      "BDNF_N       0.319088\n",
      "NR1_N        2.297269\n",
      "NR2A_N       3.843934\n",
      "               ...   \n",
      "SYP_N        0.446073\n",
      "H3AcK18_N    0.169609\n",
      "EGR1_N       0.183135\n",
      "H3MeK4_N     0.205440\n",
      "CaNA_N       1.337784\n",
      "Length: 77, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYRK1A_N</th>\n",
       "      <th>ITSN1_N</th>\n",
       "      <th>BDNF_N</th>\n",
       "      <th>NR1_N</th>\n",
       "      <th>NR2A_N</th>\n",
       "      <th>pAKT_N</th>\n",
       "      <th>pBRAF_N</th>\n",
       "      <th>pCAMKII_N</th>\n",
       "      <th>pCREB_N</th>\n",
       "      <th>pELK_N</th>\n",
       "      <th>...</th>\n",
       "      <th>pCFOS_N</th>\n",
       "      <th>SYP_N</th>\n",
       "      <th>H3AcK18_N</th>\n",
       "      <th>EGR1_N</th>\n",
       "      <th>H3MeK4_N</th>\n",
       "      <th>CaNA_N</th>\n",
       "      <th>Genotype</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MouseID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>309_1</td>\n",
       "      <td>0.503644</td>\n",
       "      <td>0.747193</td>\n",
       "      <td>0.430175</td>\n",
       "      <td>2.816329</td>\n",
       "      <td>5.990152</td>\n",
       "      <td>0.218830</td>\n",
       "      <td>0.177565</td>\n",
       "      <td>2.373744</td>\n",
       "      <td>0.232224</td>\n",
       "      <td>1.750936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108336</td>\n",
       "      <td>0.427099</td>\n",
       "      <td>0.114783</td>\n",
       "      <td>0.131790</td>\n",
       "      <td>0.128186</td>\n",
       "      <td>1.675652</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309_2</td>\n",
       "      <td>0.514617</td>\n",
       "      <td>0.689064</td>\n",
       "      <td>0.411770</td>\n",
       "      <td>2.789514</td>\n",
       "      <td>5.685038</td>\n",
       "      <td>0.211636</td>\n",
       "      <td>0.172817</td>\n",
       "      <td>2.292150</td>\n",
       "      <td>0.226972</td>\n",
       "      <td>1.596377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104315</td>\n",
       "      <td>0.441581</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>0.135103</td>\n",
       "      <td>0.131119</td>\n",
       "      <td>1.743610</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309_3</td>\n",
       "      <td>0.509183</td>\n",
       "      <td>0.730247</td>\n",
       "      <td>0.418309</td>\n",
       "      <td>2.687201</td>\n",
       "      <td>5.622059</td>\n",
       "      <td>0.209011</td>\n",
       "      <td>0.175722</td>\n",
       "      <td>2.283337</td>\n",
       "      <td>0.230247</td>\n",
       "      <td>1.561316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106219</td>\n",
       "      <td>0.435777</td>\n",
       "      <td>0.111883</td>\n",
       "      <td>0.133362</td>\n",
       "      <td>0.127431</td>\n",
       "      <td>1.926427</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309_4</td>\n",
       "      <td>0.442107</td>\n",
       "      <td>0.617076</td>\n",
       "      <td>0.358626</td>\n",
       "      <td>2.466947</td>\n",
       "      <td>4.979503</td>\n",
       "      <td>0.222886</td>\n",
       "      <td>0.176463</td>\n",
       "      <td>2.152301</td>\n",
       "      <td>0.207004</td>\n",
       "      <td>1.595086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111262</td>\n",
       "      <td>0.391691</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.147444</td>\n",
       "      <td>0.146901</td>\n",
       "      <td>1.700563</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309_5</td>\n",
       "      <td>0.434940</td>\n",
       "      <td>0.617430</td>\n",
       "      <td>0.358802</td>\n",
       "      <td>2.365785</td>\n",
       "      <td>4.718679</td>\n",
       "      <td>0.213106</td>\n",
       "      <td>0.173627</td>\n",
       "      <td>2.134014</td>\n",
       "      <td>0.192158</td>\n",
       "      <td>1.504230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110694</td>\n",
       "      <td>0.434154</td>\n",
       "      <td>0.118481</td>\n",
       "      <td>0.140314</td>\n",
       "      <td>0.148380</td>\n",
       "      <td>1.839730</td>\n",
       "      <td>Control</td>\n",
       "      <td>Memantine</td>\n",
       "      <td>C/S</td>\n",
       "      <td>c-CS-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>J3295_11</td>\n",
       "      <td>0.254860</td>\n",
       "      <td>0.463591</td>\n",
       "      <td>0.254860</td>\n",
       "      <td>2.092082</td>\n",
       "      <td>2.600035</td>\n",
       "      <td>0.211736</td>\n",
       "      <td>0.171262</td>\n",
       "      <td>2.483740</td>\n",
       "      <td>0.207317</td>\n",
       "      <td>1.057971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183324</td>\n",
       "      <td>0.374088</td>\n",
       "      <td>0.318782</td>\n",
       "      <td>0.204660</td>\n",
       "      <td>0.328327</td>\n",
       "      <td>1.364823</td>\n",
       "      <td>Ts65Dn</td>\n",
       "      <td>Saline</td>\n",
       "      <td>S/C</td>\n",
       "      <td>t-SC-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>J3295_12</td>\n",
       "      <td>0.272198</td>\n",
       "      <td>0.474163</td>\n",
       "      <td>0.251638</td>\n",
       "      <td>2.161390</td>\n",
       "      <td>2.801492</td>\n",
       "      <td>0.251274</td>\n",
       "      <td>0.182496</td>\n",
       "      <td>2.512737</td>\n",
       "      <td>0.216339</td>\n",
       "      <td>1.081150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175674</td>\n",
       "      <td>0.375259</td>\n",
       "      <td>0.325639</td>\n",
       "      <td>0.200415</td>\n",
       "      <td>0.293435</td>\n",
       "      <td>1.364478</td>\n",
       "      <td>Ts65Dn</td>\n",
       "      <td>Saline</td>\n",
       "      <td>S/C</td>\n",
       "      <td>t-SC-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>J3295_13</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.395179</td>\n",
       "      <td>0.234118</td>\n",
       "      <td>1.733184</td>\n",
       "      <td>2.220852</td>\n",
       "      <td>0.220665</td>\n",
       "      <td>0.161435</td>\n",
       "      <td>1.989723</td>\n",
       "      <td>0.185164</td>\n",
       "      <td>0.884342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158296</td>\n",
       "      <td>0.422121</td>\n",
       "      <td>0.321306</td>\n",
       "      <td>0.229193</td>\n",
       "      <td>0.355213</td>\n",
       "      <td>1.430825</td>\n",
       "      <td>Ts65Dn</td>\n",
       "      <td>Saline</td>\n",
       "      <td>S/C</td>\n",
       "      <td>t-SC-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>J3295_14</td>\n",
       "      <td>0.221242</td>\n",
       "      <td>0.412894</td>\n",
       "      <td>0.243974</td>\n",
       "      <td>1.876347</td>\n",
       "      <td>2.384088</td>\n",
       "      <td>0.208897</td>\n",
       "      <td>0.173623</td>\n",
       "      <td>2.086028</td>\n",
       "      <td>0.192044</td>\n",
       "      <td>0.922595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196296</td>\n",
       "      <td>0.397676</td>\n",
       "      <td>0.335936</td>\n",
       "      <td>0.251317</td>\n",
       "      <td>0.365353</td>\n",
       "      <td>1.404031</td>\n",
       "      <td>Ts65Dn</td>\n",
       "      <td>Saline</td>\n",
       "      <td>S/C</td>\n",
       "      <td>t-SC-s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>J3295_15</td>\n",
       "      <td>0.302626</td>\n",
       "      <td>0.461059</td>\n",
       "      <td>0.256564</td>\n",
       "      <td>2.092790</td>\n",
       "      <td>2.594348</td>\n",
       "      <td>0.251001</td>\n",
       "      <td>0.191811</td>\n",
       "      <td>2.361816</td>\n",
       "      <td>0.223632</td>\n",
       "      <td>1.064085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187556</td>\n",
       "      <td>0.420347</td>\n",
       "      <td>0.335062</td>\n",
       "      <td>0.252995</td>\n",
       "      <td>0.365278</td>\n",
       "      <td>1.370999</td>\n",
       "      <td>Ts65Dn</td>\n",
       "      <td>Saline</td>\n",
       "      <td>S/C</td>\n",
       "      <td>t-SC-s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1080 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DYRK1A_N   ITSN1_N    BDNF_N     NR1_N    NR2A_N    pAKT_N  \\\n",
       "MouseID                                                                \n",
       "309_1     0.503644  0.747193  0.430175  2.816329  5.990152  0.218830   \n",
       "309_2     0.514617  0.689064  0.411770  2.789514  5.685038  0.211636   \n",
       "309_3     0.509183  0.730247  0.418309  2.687201  5.622059  0.209011   \n",
       "309_4     0.442107  0.617076  0.358626  2.466947  4.979503  0.222886   \n",
       "309_5     0.434940  0.617430  0.358802  2.365785  4.718679  0.213106   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "J3295_11  0.254860  0.463591  0.254860  2.092082  2.600035  0.211736   \n",
       "J3295_12  0.272198  0.474163  0.251638  2.161390  2.801492  0.251274   \n",
       "J3295_13  0.228700  0.395179  0.234118  1.733184  2.220852  0.220665   \n",
       "J3295_14  0.221242  0.412894  0.243974  1.876347  2.384088  0.208897   \n",
       "J3295_15  0.302626  0.461059  0.256564  2.092790  2.594348  0.251001   \n",
       "\n",
       "           pBRAF_N  pCAMKII_N   pCREB_N    pELK_N  ...   pCFOS_N     SYP_N  \\\n",
       "MouseID                                            ...                       \n",
       "309_1     0.177565   2.373744  0.232224  1.750936  ...  0.108336  0.427099   \n",
       "309_2     0.172817   2.292150  0.226972  1.596377  ...  0.104315  0.441581   \n",
       "309_3     0.175722   2.283337  0.230247  1.561316  ...  0.106219  0.435777   \n",
       "309_4     0.176463   2.152301  0.207004  1.595086  ...  0.111262  0.391691   \n",
       "309_5     0.173627   2.134014  0.192158  1.504230  ...  0.110694  0.434154   \n",
       "...            ...        ...       ...       ...  ...       ...       ...   \n",
       "J3295_11  0.171262   2.483740  0.207317  1.057971  ...  0.183324  0.374088   \n",
       "J3295_12  0.182496   2.512737  0.216339  1.081150  ...  0.175674  0.375259   \n",
       "J3295_13  0.161435   1.989723  0.185164  0.884342  ...  0.158296  0.422121   \n",
       "J3295_14  0.173623   2.086028  0.192044  0.922595  ...  0.196296  0.397676   \n",
       "J3295_15  0.191811   2.361816  0.223632  1.064085  ...  0.187556  0.420347   \n",
       "\n",
       "          H3AcK18_N    EGR1_N  H3MeK4_N    CaNA_N  Genotype  Treatment  \\\n",
       "MouseID                                                                  \n",
       "309_1      0.114783  0.131790  0.128186  1.675652   Control  Memantine   \n",
       "309_2      0.111974  0.135103  0.131119  1.743610   Control  Memantine   \n",
       "309_3      0.111883  0.133362  0.127431  1.926427   Control  Memantine   \n",
       "309_4      0.130405  0.147444  0.146901  1.700563   Control  Memantine   \n",
       "309_5      0.118481  0.140314  0.148380  1.839730   Control  Memantine   \n",
       "...             ...       ...       ...       ...       ...        ...   \n",
       "J3295_11   0.318782  0.204660  0.328327  1.364823    Ts65Dn     Saline   \n",
       "J3295_12   0.325639  0.200415  0.293435  1.364478    Ts65Dn     Saline   \n",
       "J3295_13   0.321306  0.229193  0.355213  1.430825    Ts65Dn     Saline   \n",
       "J3295_14   0.335936  0.251317  0.365353  1.404031    Ts65Dn     Saline   \n",
       "J3295_15   0.335062  0.252995  0.365278  1.370999    Ts65Dn     Saline   \n",
       "\n",
       "          Behavior   class  \n",
       "MouseID                     \n",
       "309_1          C/S  c-CS-m  \n",
       "309_2          C/S  c-CS-m  \n",
       "309_3          C/S  c-CS-m  \n",
       "309_4          C/S  c-CS-m  \n",
       "309_5          C/S  c-CS-m  \n",
       "...            ...     ...  \n",
       "J3295_11       S/C  t-SC-s  \n",
       "J3295_12       S/C  t-SC-s  \n",
       "J3295_13       S/C  t-SC-s  \n",
       "J3295_14       S/C  t-SC-s  \n",
       "J3295_15       S/C  t-SC-s  \n",
       "\n",
       "[1080 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "print(df.mean())\n",
    "df1 = df.fillna(df.mean())\n",
    "df1\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification for Down's Syndrome\n",
    "\n",
    "We will first predict the binary class label in `df1['Genotype']` which indicates if the mouse has Down's syndrome or not.  Get the string values in `df1['Genotype'].values` and convert this to a numeric vector `y` with 0 or 1.  You may wish to use the `np.unique` command with the `return_inverse=True` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Control' 'Control' 'Control' ... 'Ts65Dn' 'Ts65Dn' 'Ts65Dn']\n",
      "['Control' 'Ts65Dn']\n",
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "print( df1['Genotype'].values )\n",
    "labels, y = np.unique(df1['Genotype'].values, return_inverse=True)\n",
    "print (labels)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predictors, get all but the last four columns of the dataframes.  Standardize the data matrix and call the standardized matrix `Xs`.  The predictors are the expression levels of the 77 genes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "df_4=df1.iloc[:,:-4]\n",
    "df_4\n",
    "Xs = preprocessing.scale(df_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `LogisticRegression` object `logreg` and `fit` the training data. Use `C = 1e5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "Xs_train, Xs_test, Y_train, Y_test = model_selection.train_test_split( Xs, y, test_size=0.33)\n",
    "logreg.fit(Xs_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy of the classifer.  That is, use the `logreg.predict` function to predict labels `yhat` and measure the fraction of time that the predictions match the true labels. Also, plot the ROC curve, and measure the AUC. Later, we will properly measure the accuracy and AUC on cross-validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right: 0.957983193277311 vs Wrong: 0.04201680672268904\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "yhat = logreg.predict(Xs_test)\n",
    "acc = np.mean(yhat==Y_test)\n",
    "print(f\"Right: {acc} vs Wrong: {1-acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# ROC BOIZ\n",
    "yprob = logreg.predict_proba(Xs_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test,yprob[:,1])\n",
    "\n",
    "plt.plot(fpr,tpr)\n",
    "plt.grid()\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.ylim([0.3,1])\n",
    "plt.xlim([0,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Threshold')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU9b3/8dcne0LYCYIsEhFlURaNiCKbaEGs4lrB1mutlbqiolJ7vVet/f2uFqy1Vm5xa12u1722uFBcCMQNJCqCoOwoQYQY1rBl4Xv/mDMwCRMyITOZnMn7+XjkkTNnmfPhZHjPd75nzveYcw4REfG/pHgXICIi0aFAFxFJEAp0EZEEoUAXEUkQCnQRkQSREq8dt2vXznXr1i1euxcR8aVPP/30B+dcTrhlcQv0bt26UVhYGK/di4j4kpl9U9MydbmIiCQIBbqISIJQoIuIJIi49aGLiERDeXk5RUVF7NmzJ96lRFVGRgadO3cmNTU14m0U6CLia0VFRTRv3pxu3bphZvEuJyqcc5SUlFBUVERubm7E29Xa5WJmfzWzTWb2ZQ3LzcweNrOVZrbIzE6sQ90iIvWyZ88e2rZtmzBhDmBmtG3bts6fOiLpQ38KGH2I5WcDPbyfCcBf6lSBiEg9JVKYBx3Ov6nWQHfOFQCbD7HKWOAZFzAPaGVmHetcSYS+mj+L+U/eyqYt22O1CxERX4pGH3onYF3I4yJv3obqK5rZBAKteLp27XpYO9u2/EMGrXuCcf87hvNP7hF2nYzUZFpmpdIyM5VWmYHfLTNTSUnWl3pEJLpKSkoYOXIkAN9//z3Jycnk5AQu5Pziiy/o168fFRUV9OrVi6effpqsrCySk5M54YQTqKioIDc3l2effZZWrVrVu5YGPSnqnHsMeAwgLy/vsO6sMejotrAKFhdtZd66xXXaNjs9ZX+4t8xMpVXWgekDbwBpVZa3yEyleXoKSUmJ95FOROqvbdu2LFy4EIB77rmH7OxsbrvtNgCys7P3L/vpT3/K9OnTmTRpEpmZmfvnX3HFFUybNo0777yz3rVEI9DXA11CHnf25sVIIFgLbh9OWXLWQUudg93llWzbXc62XeVs213O1l1lbNtdEZjeXcb23eVs3VXOyk2l3rxyyir21bjHJIMWmQda/C0yU2mVlUbLzJSqbwIhbxCpYT4NpCQZHVtlkJ6SHL3DISK+MGTIEBYtWnTQ/FNPPTXs/MMRjUCfAdxgZi8ApwDbnHMHdbdEjXeioG2zNEjPjNrT7imvZKv3BnDgTSD0ccj07nKKtuzev86+OnzWSE4yurbJ4uh2zejePpvuOc3onpNNbrtmZKVF9wNTekqSPllIk/Lb15ew9Lvonl/rfWQL7j63T72eo6KigpkzZzJ6dNXvl1RWVvLee+9x1VVX1ev5g2pNEDN7HhgOtDOzIuBuIBXAOTcdeAsYA6wEdgFXRqWy2kT5XqgZqcl0aJlMh5YZdSzDUbq3okrgb9tdTkWYlC+r2Mc3JTtZVVzKqk07eX/FD5RV1vzJoL7M2P+polVWGq2yDp5u3SzN615Ko3VW4NNG8wx1MYlEw+7du+nfvz8QaKEHgzs4f/369fTq1YuzzjorKvurNdCdc+NrWe6A66NSTUSCQdM4bm5tZjTPSKV5RmqVfqdIVO5zrN+ym1XFpaz5YWdUw9052F1Wwdbd5WzZFfjEsXlnGauKS9m6q5wdeypq3DYp+EaQFQj71lkHpltlpdLae0MILAu+OeiNQOKvvi3paAvtKw83f9euXYwaNYpp06YxceLEeu/Pf1eKJtD3TZOTjK5ts+jaNosRDbzvisp9+7uPtnqBv3VX8HHV6R9Ky1hZxzeCgz8NeL+9N4dWmQemddJZmqqsrCwefvhhzj//fK677jpSUuoXyf4L9KAod7k0NSnJSbTNTqdtdnqdtiuv3Bc4qRwa/LvK2eKdTwid/qG0jBWbStm2q5wde2t/I2idlUbLYFfQ/uk0WjdLPahbqGVWKi0yUhLyghJpWgYMGEDfvn15/vnnufzyy+v1XD4MdP0HjqfUerwRHDi5XMaWnQfeFLbtDrwJBM9DFJfujeiNIDnJDlxrEOwKykwlOyOFpFqCvlvbLK44LXHG/pDG4Z577qnyuLS0NOx61ee//vrrUdm/DwM9SC10P0lNTqJddjrt6vFGEL5b6MCnhE079rB8445DdgsB7HOOHXsqWLphO91zsgFo0yyNCwZ00sVn4mv+C/Rgi0pdLk3C4b4RHIpzjsmvLOKlwqIq8z9eXcJ/XXACGam6TkD8yX+Bri4XqSczY+ol/bh37PE475PeLS8u5O+freeETi25cnDkw5WKNCb6fClNVmZaMllpKWSlpfCXn55EVloyn6w51Dh0Io2b/wJdXS4SA0lJxqg+HViwdgtOry3xKf8FurpcJEZOOqo1P5Tu5dvNu+Jdishh8WGgB6kVJdF1crc2ACxYuyXOlYjfJCcn079///0/a9euZc6cObRs2ZL+/fvTq1cvfvvb3wJUmd+zZ8/9IzNGg/9Oiup7wxIjPdpn0yIjhU+/2czFJ3WOdzniI+Eu8V+7di1DhgzhjTfeYOfOnfTv359zzz0XYP/83bt3M2DAAC644AIGDx5c7zr820JXP6dEWVKSceJRrSlUC12irFmzZpx00kmsXLmyyvzMzMz9g3RFg/9a6Psp0CX6Tu7WhjnLllFSurfOV8NKIzDzDvi+bje+qVWHE+Ds+w+5Suioirm5ubz22mtVlpeUlDBv3jz+8z//k+Li4v3zt2zZwooVKxg6dGhUSvVfoKvLRWKoozd8ctGW3Qp0iVhNoyq+//77DBgwgKSkJO644w769OnDnDlzeP/99+nXrx8rVqzg5ptvpkOHDlGpw3+BHqQuF4mB1s3SgMDwAOJDtbSkG1qwr7ym+WvWrGHQoEH85Cc/2d/Crw8f9qE3rvHQRUQOV25uLnfccQe///3vo/J8/gt0dbmISAK55pprKCgoYO3atfV+LnW5iIjUU7hhcocPH87w4cNrnZ+ZmRm1b7n4r4WuK0VFRMLyYaAHqYUuIhLKf4GuwblEpJpEHFDtcP5N/gt0dbmISIiMjAxKSkoSKtSdc5SUlJCRkVGn7fx7UlRdLiICdO7cmaKioipXYCaCjIwMOneu25hC/gt0dbmISIjU1FRyc3WXKVCXi0hYai6IH/kw0IP0X06iT80F8TP/BbquFBURCct/gR6kPnQRkSp8GOganEtEJBz/Bbq6XEREwvJfoAepy0VEpIqIAt3MRpvZMjNbaWZ3hFne1czyzexzM1tkZmOiX+r+vXm/FegiIqFqDXQzSwamAWcDvYHxZta72mr/AbzknBsAjAP+O9qFhhQUs6cWEfGzSFroA4GVzrnVzrky4AVgbLV1HNDCm24JfBe9EmugLhcRkSoiCfROwLqQx0XevFD3AD8zsyLgLeDGcE9kZhPMrNDMCg9/3AW10EVEwonWSdHxwFPOuc7AGOBZMzvouZ1zjznn8pxzeTk5OVHatYiIQGSBvh7oEvK4szcv1FXASwDOuY+BDKBdNAo8iAbnkgagl5f4USSBvgDoYWa5ZpZG4KTnjGrrfAuMBDCzXgQCPUZjWarLRWLHdNJdfKzWQHfOVQA3ALOArwh8m2WJmd1rZud5q90KXG1mXwDPAz93MR9tXk0oEZFQEY2H7px7i8DJztB5d4VMLwUGR7e0GqjLRUQkLP9eKSoiIlX4ONDVQhcRCeW/QNdJKxGRsPwX6EHqQxcRqcKHga7BuUREwvFfoKvLRUQkLP8FepC6XEREqvBhoKvLRWJnn9dQ2FNeGedKROrOf4GuLheJob1ekGek+u+/hoh/X7XqcpEYyEqL6OJpkUbJh4GuFrqISDg+DPQgtdBFREL5L9A1OJeISFj+C3R1uYiIhOXDQA9SC11EJJT/Al1dLiIiYfkv0NXlIiISlg8DPUgtdBGRUP4LdF0pKiISlv8CPUh96CIiVfgw0DU4l4hIOP4LdHW5iIiE5b9AD1IDXUSkCh8GurpcRETC8V+gq8tFRCQs/wV6kL7lIiJShQ8DXS10EZFwfBjoQWqhi4iE8l+g7z8nqkAXEQnlv0BXl4uISFgRBbqZjTazZWa20szuqGGdn5jZUjNbYmb/G90yw1ELXUQkVK23ODezZGAacBZQBCwwsxnOuaUh6/QAfgMMds5tMbP2sSpY46GLiIQXSQt9ILDSObfaOVcGvACMrbbO1cA059wWAOfcpuiWGUpdLiIi4UQS6J2AdSGPi7x5oY4FjjWzD81snpmNDvdEZjbBzArNrLC4uPjwKt5PLXQRkVDROimaAvQAhgPjgcfNrFX1lZxzjznn8pxzeTk5OYe3J10pKiISViSBvh7oEvK4szcvVBEwwzlX7pxbAywnEPCxoz50EZEqIgn0BUAPM8s1szRgHDCj2jr/INA6x8zaEeiCWR3FOkNocC4RkXBqDXTnXAVwAzAL+Ap4yTm3xMzuNbPzvNVmASVmthTIB253zpXEpGJ1uYiIhFXr1xYBnHNvAW9Vm3dXyLQDJnk/DUNdLiIiVfj4SlEFuohIKP8FurpcRETC8l+gB6nLRUSkCh8GulroIiLh+DDQg9RCFxEJ5b9A1+BcIiJh+S/Q1eUiIhKWDwM9SC10EZFQ/gt0dbmIiITlv0BXl4uISFg+DPQgtdBFREL5L9B1paiISFj+C/QgNdBFRKrwYaBrcC4RkXD8F+jqchERCct/gR6kry2KiFThw0BXl4uISDj+C3T1uIiIhOW/QA9Sl4uISBU+DHQ10UVEwvFhoAephS4iEsp/ga7BuUREwvJfoKvLRUQkLB8GepBa6CIiofwX6OpyEREJy3+Bri4XEZGwfBjoQWqhi4iE8l+ga3AuEZGw/BfoQepDFxGpwoeBrsG5RETC8V+gq8tFRCSsiALdzEab2TIzW2lmdxxivYvMzJlZXvRKrIG6XEREqqg10M0sGZgGnA30BsabWe8w6zUHbgLmR7vIanvyfivQJfoyUpMBuHvGEgqWF+PUcBAfiaSFPhBY6Zxb7ZwrA14AxoZZ73fA74E9UazvYOpykRg6uVtr/nBJP7bsLOff/voJ4x+fx2ffbol3WSIRiSTQOwHrQh4XefP2M7MTgS7OuTcP9URmNsHMCs2ssLi4uM7FVqGWk8SAmXHRSZ2Zfdsw7jm3Nys2lnLhf3/E1c8Usuz7HfEuT+SQ6n1S1MySgAeBW2tb1zn3mHMuzzmXl5OTc7h7PMztRCKXnpLMzwfnUjB5BLeedSzzVpUw+k8FTHpxIes274p3eSJhRRLo64EuIY87e/OCmgPHA3PMbC0wCJgR+xOjaqFL7DVLT+HGkT0omDyCCUOO5s3FGzjjD3O4+59fUrxjb7zLE6kikkBfAPQws1wzSwPGATOCC51z25xz7Zxz3Zxz3YB5wHnOucKYVKzBuSQOWjdL4zdjejH39hFcfFIX/mf+twydks/UWV+zbXd5vMsTASIIdOdcBXADMAv4CnjJObfEzO41s/NiXeDB1OUi8dOhZQb3XXgC704axpm9j2Ba/iqGTsln+txV7C6rjHd50sRZvL6WlZeX5woLD6MRX7wcpp0MFz0JJ1wc/cJE6uDL9dt44O1lzFlWTPvm6Uwc2YNLT+5CarL/rtkTfzCzT51zYbu0/feqU5eLNCLHd2rJU1cO5MUJg+jSJov/+MeXnPngXP65cD379uk1Kg3Lf4GuLhdphE45ui2vXHMqT16RR2ZqMje9sJBz/vwBs7/eqIuTpMH4MNCD9J9EGhczY2SvI3hr4hD+NK4/O/dW8IunCvnJox+zYO3meJcnTYD/Al1Xikojl5RkjO3fiXcnDeN35x/P2pJdXDL9Y6782ycs+W5bvMuTBOa/QA/Sx1hp5NJSkrh80FEU3D6CX4/uyaffbOGchz9g4vOfs/aHnfEuTxKQfwNdXS7iE5lpyVw7vDvvTz6D64Z3552lGznzwbn8+2uL2bg9tkMfSdPiv0BXl4v4VMusVCaP7sncycO57JSuvLRgHUOn5HPfzK/Yuqss3uVJAvBfoAepy0V8qn3zDO4dezyzbx3OmBM68ljBaoZMyeeR2SvYubci3uWJj/kw0DUeuiSGrm2z+OOl/Zl50xBOyW3DA28vZ9jUfJ7+aC1lFfviXZ74kP8CXV0ukmB6dmjBE1eczKvXnkr3nGzunrGEM/4wh1c/LaJSFydJHfgv0IPU5SIJ5qSj2vDChEE8/YuBtMxM5daXv+DsPxXw9pLvdXGSRMSHga4WuiQuM2PYsTm8fsPpPHLZACoqHROe/ZQL//IRH636Id7lSSPnw0APUotFEldSkvHjvkfy9i1Duf/CE9iwdQ+XPT6fy5+cz+IiXZwk4fkv0DU4lzQhKclJjBvYlTm3D+fOMb34cv02zn3kA6577lNWbiqNd3nSyPgv0NXlIk1QRmoyVw89moLJI5g4sgdzlhXzoz/O5devLOK7rbvjXZ40Ej4M9CC10KXpaZ6RyqSzjqVg8giuOK0br32+nuEPzOF3byylpFS3xGvq/Bfo6nIRoV12Onef24fZtw1jbL8j+duHaxg6JZ+H3l1OqS5OarL8F+jqchHZr3PrLKZe0o9ZNw9lSI8cHnp3BUOn5PPE+6vZU65b4jU1Pgz0ILXQRYJ6HNGc6ZefxD+uH0yvjs35f29+xRkPzOGlBeuoqNRVp02F/wJdV4qK1Kh/l1Y898tBPPfLU8hpns7kVxcx6qEC3lq8QRcnNQH+C/QgvThFajT4mHb84/rBTP/ZSZgZ1z33GWOnfcj7K4oV7AnMh4GuwblEImFmjD6+A7NuHsrUi/tSUlrG5U9+wmWPz+fzb7fEuzyJAf8FurpcROokOcm4JK8Ls28bxt3n9mb5xh1c8N8fMeGZQpZv3BHv8iSK/BfoQfrYKFIn6SnJXDk4l7mTRzDprGP5eFUJox4qYNJLC1m3eVe8y5Mo8GGgq8tFpD6y01OYOLIHBZNHcPWQo3lz0QbO+MMc7pmxhOIdujjJz/wX6OpyEYmK1s3S+PcxvZhz+3AuPqkzz877hmFT83lg1jK27ymPd3lyGPwX6EHqchGJio4tM7nvwr68c8tQzujZnkfyVzLk9/k8OneVLk7yGR8GulroIrFwdE42j1x2Im/ceDr9u7TivplfM2xqPs/N/4ZyXZzkCz4MdBGJpeM7teTpXwzkxQmD6Nw6iztf+5KzHpzLjC++Y59uideo+S/QNTiXSIM45ei2vHLNqTx5RR4ZqclMfP5zfvznD8j/epMuTmqkIgp0MxttZsvMbKWZ3RFm+SQzW2pmi8zsPTM7Kvql7t9b7J5aRKowM0b2OoI3Jw7hoUv7U7q3giufWsClj86jcO3meJcn1dQa6GaWDEwDzgZ6A+PNrHe11T4H8pxzfYFXgCnRLvRgaiGINJTkJOP8AZ14d9Iwfje2D2tKdnLx9I/5xVMLWPrd9niXJ55IWugDgZXOudXOuTLgBWBs6ArOuXznXPDKhHlA5+iWGUJdLiJxk5aSxOWndmPu7cOZPPo4Ctdu5pw/v89NL3zONyU7411ekxdJoHcC1oU8LvLm1eQqYGa4BWY2wcwKzaywuLg48ipFpFHJSkvhuuHH8P7kM7hmWHdmLfmekX+Yy52vLWbj9j3xLq/JiupJUTP7GZAHTA233Dn3mHMuzzmXl5OTU8+9qYUuEm8ts1L59eieFNw+gvEDu/LignUMm5rP/TO/ZtsuXZzU0CIJ9PVAl5DHnb15VZjZmcCdwHnOudhdP6wrRUUanfYtMvjd+cfz3q3DGN2nA48WrOL0KbOZlr+SXWW6JV5DiSTQFwA9zCzXzNKAccCM0BXMbADwKIEw3xT9MsNQH7pIo3NU22Y8NG4Ab00cwim5bZg6axlDp8zhmY/XUlahi5NirdZAd85VADcAs4CvgJecc0vM7F4zO89bbSqQDbxsZgvNbEYNTxcFGpxLpLHr1bEFT1xxMq9eeypH5zTjrn8uYeSDc/j7Z0VU6uKkmLF4XSCQl5fnCgsL677hnm1wf1cY9V9w6vXRL0xEoso5x9zlxUydtYwl323nuCOac9uo4zizV3tMXah1ZmafOufywi3z35WiQepyEfEFM2P4ce15/YbT+fP4AZRV7uPqZwq56C8fMW91SbzLSyg+DHR1uYj4UVKScW6/I3n7lqHcd+EJfLd1D+Mem8e//fUTvly/Ld7lJQT/Bbo+oon4WmpyEuMHdmXO7cP59zE9WVS0lR//+QOuf+4zVhWXxrs8X/NfoAepy0XE1zJSk5kwtDsFk0cw8YxjyF+2iR/9sYA7Xl3Ehm27412eL/kw0NVCF0kkLTJSmfSj4yiYPILLBx3F3z9bz7Cpc/j/by5l886yeJfnKz4M9CC10EUSSbvsdO45rw+zbxvGef2O5MkP1jB0Sj5/encFpXt1cVIk/BfoGpxLJKF1bp3FA5f0Y9bNQxl8TFv++O5yhk3J568frGFvhW6Jdyj+C3R1uYg0CT2OaM6jl+fxj+sH07Njc+59YylnPDCXlwrXUaFb4oXlw0APUgtdpCno36UVz/1yEP9z1Sm0zU5j8iuLGPVQAf/6coPunFSN/wJdXS4iTdLpPdrxz+sHM/1nJ2JmXPM/n3H+tA/5YMUP8S6t0fBfoKvLRaTJMjNGH9+Rf900hCkX9+WH0jJ+9uR8Lnt8HgvXbY13eXHnw0APUgtdpKlKSU7iJ3ldmH3bMO76cW+Wfb+D86d9yK+eLWTFxh3xLi9u/BfoulJURDzpKcn84vRc5k4ewS1nHsuHK0sY9VABt738BUVbdtX+BAnGf4EepD50EfFkp6dw05k9KJg8gqtOz2XGF99xxgNzuWfGEn4ojd39dhobHwa6BucSkfDaNEvjznN6M+e24Vx4YieenfcNQ6fk8+Dby9i+J/Fviee/QA92uXz5GpTrZrQicrAjW2Vy/0V9efuWoYzo2Z6HZ69k6JR8HitYxZ7yxL04yYeBngzN2sOmJfBwf/jkcahoOh+pRCRy3XOymXbZibxx4+n07dyK/3rra4ZPncPzn3ybkBcn+e+ORQBlu2DdPJg7Fb79CFp0giG3woDLISUtuoWKSMKYt7qEKf/6ms++3Upuu2ZMOutYzjmhI0lJ/vmyxaHuWOTPQA9yDlbPgTn3wbr50LJLINh7nEXcv6+efQQkp8S3BhE5iHOOd7/axAOzlrFs4w76HNmC20cdx7Bjc3xxS7zEDfQg52DV7ECwFy2IznPWV3I6HNEbOvSFjn2hQ7/A45SMmrdJSm64+kSauMp9jhlfrOfBd5azbvNuBua24dejj+Oko9rEu7RDSvxAD3IO1hTAlrXRfd4611EJJatgwxfw/aLAja0jkdk60H3U4kho3vHAdIsjD0xntIht7SJNTFnFPl5Y8C0Pv7eSH0r3MrJne24bdRy9OjbO/2tNJ9AbI+dg67eBYP9hOeyr4Qy72wc7i2H7d7B9feD3zuKD10vLPjjkWxwJzUPmZbXRBVgidbSrrIK/fbiW6XNXUbq3grH9jmTSWcfRtW1WvEurQoHuVxV7YccG2L7hQMiHBv6ODYEfV+1sfXI6tOgYCP+mKDULugyEbqdD11Mhs1W8KxIf2bqrjOlzV/PUR2uoqHSMH9iVG884hvYtDtFd2oAU6ImssgJ2bqoa9MGfiib6Pf1dJbD+M6jcCxh0OB6OOh2OOg2OGgzN2sa7QvGBjdv38OfZK3jhk3WkJBtXDs7lmqHdaZmVGte6FOjS9JTvgfWFsPZD+OZDWPcJVHg3Hs7pBR37QZeT4eRfxrdOafS+KdnJg+8sZ8YX39E8PYVrhnfnytNyyUyLz5cYFOgiFWXw3efwzQeBkN/4JZRuhAsehX7j4l2d+MBXG7bzwKxlvPf1JnKapzPxjGO49OSupKU07PWZCnSR6ior4JnzAiF/dT607xnvisQnCtduZsq/lvHJ2s10bZPFpLOO5bx+RzbYxUmHCnT/XfovEg3JKXDRk4ETqC9fAWU7412R+ERetza8+KtB/O3Kk8lOT+HmFxcy5uH3eXfpxrjfEk+BLk1Xi45w0RNQvAxevjJwIlkkAmbGiOPa88aNp/Pw+AHsKa/kl88UcvH0j5m/uiR+danLRZq8/Ptg7v2BQd+unBn4mmOzdvGuSnykvHIfLxcW8af3lrNx+16GHZvD7aOO4/hOLaO+L/WhixyKczB/OvzrDm+GwY2fQtvucS1L/GdPeSVPf7SWv8xdxdZd5fy4b0du/dFx5LZrFrV91LsP3cxGm9kyM1tpZneEWZ5uZi96y+ebWbf6lSzSgMxg0LXw01dg4ATAwbaieFclPpSRmsyvhnWnYPIIbjzjGGZ/vYkzH5zLb/6+iA3bdsd8/7W20M0sGVgOnAUUAQuA8c65pSHrXAf0dc5dY2bjgAucc5ce6nnVQpdGadlMeN77GmNmG7Ckaj9W7XfID9XnHWLd/dtQ87Katj9oP/Xdl9UwXZ99WQ3LazpGNe0r+FND7Ryi9hrrs0Psq9rz1VPxjr1My1/Jc/O/wcz4+WnduHZYd1o3O/xhvg/VQo9kfNeBwErn3GrvyV4AxgJLQ9YZC9zjTb8CPGJm5uJ9ylekrroNCQzBvLc0MKTCQT8OcDUs85ZX+e39HLSNq2G6rvsKs7yu+9LtHGtWzze3HIx7zLiznbF1dwXb51WyeX4SqwbeQt45V0e93EgCvROwLuRxEXBKTes45yrMbBvQFvghdCUzmwBMAOjatethliwSQ+nZMPKueFfRsIJvDDW+eRziDSHsNjW8qR20zaG2DfP4kPXVtq9anru+b9i1vJGmOkeO20f6njKWb9hGm7ZHxORP2aB3YHDOPQY8BoEul4bct4jUwCyke0Fj8sdSCyBsX0mURHJSdD3QJeRxZ29e2HXMLAVoCcTvy5giIk1QJIG+AOhhZrlmlgaMA2ZUW2cGcIU3fTEwW/3nIiINq9YuF69P/AZgFoHPY391zi0xs3uBQufcDOBJ4FkzWwlsJhD6IiLSgCLqQ3fOvQW8VW3eXSHTe4BLoluaiIjUhcZyERFJEAp0EZEEoUAXEUkQCnQRkQQRt9EWzawY+OYwN29HtatQG+A3IiYAAAdiSURBVAnVVTeqq+4aa22qq27qU9dRzrmccAviFuj1YWaFNQ1OE0+qq25UV9011tpUV93Eqi51uYiIJAgFuohIgvBroD8W7wJqoLrqRnXVXWOtTXXVTUzq8mUfuoiIHMyvLXQREalGgS4ikiAaXaDX54bUZvYbb/4yMxvVwHVNMrOlZrbIzN4zs6NCllWa2ULvp/rQw7Gu6+dmVhyy/1+GLLvCzFZ4P1dU3zbGdf0xpKblZrY1ZFksj9dfzWyTmX1Zw3Izs4e9uheZ2Ykhy2JyvCKo6adeLYvN7CMz6xeybK03f6GZRf0mvRHUNtzMtoX8ve4KWXbI10CM67o9pKYvvddUG29ZTI6ZmXUxs3wvB5aY2U1h1ont68s512h+CAzPuwo4GkgDvgB6V1vnOmC6Nz0OeNGb7u2tnw7kes+T3IB1jQCyvOlrg3V5j0vjeLx+DjwSZts2wGrvd2tvunVD1VVt/RsJDMsc0+PlPfdQ4ETgyxqWjwFmErgt8SBgfgMcr9pqOi24L+DsYE3e47VAuzger+HAG/V9DUS7rmrrnkvgHg0xPWZAR+BEb7o5sDzM/8eYvr4aWwt9/w2pnXNlQPCG1KHGAk97068AI83MvPkvOOf2OufWACu952uQupxz+c65Xd7DeQTu7BRrkRyvmowC3nHObXbObQHeAUbHqa7xwPNR2vchOecKCIzZX5OxwDMuYB7Qysw6EsPjVVtNzrmPvH1Cw722gvuu7XjVpD6vzWjX1SCvL+fcBufcZ970DuArAvdbDhXT11djC/RwN6SufkCq3JAaCN6QOpJtY1lXqKsIvAsHZZhZoZnNM7Pzo1RTXeq6yPt494qZBW8n2CiOl9c1lQvMDpkdq+MViZpqj+Xxqovqry0HvG1mn1rgJuzxcKqZfWFmM82sjzevURwvM8siEIyvhsyO+TGzQFfwAGB+tUUxfX016E2imwIz+xmB+8AOC5l9lHNuvZkdDcw2s8XOuVUNVNLrwPPOub1m9isCn27OaKB9R2Ic8IpzrjJkXjyPV6NlZiMIBPrpIbNP945Ve+AdM/vaa702lM8I/L1KzWwM8A+gRwPuvzbnAh8650Jb8zE9ZmaWTeAN5Gbn3PZoPW8kGlsLvT43pI5k21jWhZmdCdwJnOec2xuc75xb7/1eDcwh8M7dIHU550pCankCOCnSbWNZV4hxVPs4HMPjFYmaao/l8aqVmfUl8Pcb65zbfwP2kGO1CXiN6HUzRsQ5t905V+pNvwWkmlk74ny8Qhzq9RX1Y2ZmqQTC/Dnn3N/DrBLb11e0TwzU86RCCoGTAbkcOJHSp9o611P1pOhL3nQfqp4UXU30TopGUtcAAieBelSb3xpI96bbASuI0smhCOvqGDJ9ATDPHTgJs8arr7U33aah6vLW60ngBJU1xPEK2Uc3aj7Jdw5VT1p9EuvjFUFNXQmcEzqt2vxmQPOQ6Y+A0dE8VhHU1iH49yMQjN96xy6i10Cs6vKWtyTQz96sIY6Z9+9+BnjoEOvE9PUV1T98lA7KGAJnh1cBd3rz7iXQ6gXIAF72XuCfAEeHbHunt90y4OwGrutdYCOw0PuZ4c0/DVjsvaAXA1c1cF33AUu8/ecDPUO2/YV3HFcCVzZkXd7je4D7q20X6+P1PLABKCfQT3kVcA1wjbfcgGle3YuBvFgfrwhqegLYEvLaKvTmH+0dpy+8v/Gd0TxWEdZ2Q8jrax4hbzrhXgMNVZe3zs8JfFEidLuYHTMCXWEOWBTytxrTkK8vXfovIpIgGlsfuoiIHCYFuohIglCgi4gkCAW6iEiCUKCLiCQIBbr4jpm1DRlJ73szW+9NbzWzpTHY33Aze6OO28wxs4NuAmyB0S8fiV51Igco0MV3XODq1/7Ouf7AdOCP3nR/YF9t23tXGIskHAW6JJpkM3vcG4/6bTPLhP0t5oe88a9vMrMcM3vVzBZ4P4O99YaFtP4/N7Pm3vNme4ObfW1mz3kjfGJmI731FntjdKdXL8jMrrTAmO+fAIMb6DhIE6RAl0TTA5jmnOsDbAUuClmW5pzLc879AfgTgZb9yd46T3jr3AZc77X4hwC7vfkDgJsJjLt/NDDYzDKAp4BLnXMnELjc/drQYryhUX9LIMhP97YXiQkFuiSaNc65hd70pwTG+wh6MWT6TOARM1sIzABaeKPkfQg8aGYTgVYuMEQzBMbcKHLO7SNwSXc34Dhvf8u9dZ4mcOOFUKcAc5xzxS4wLviLiMSI+hIl0ewNma4EMkMe7wyZTgIGOef2VNv+fjN7k8AYHB/agVsZVn9e/d+RRkctdGmq3iZw6zsAzKy/97u7c26xc+73wAICI0LWZBnQzcyO8R5fDsytts58YJj3zZxU4JJo/QNEqlOgS1M1Ecjz7uS0lMCIeAA3ezcVXkRgJL+ZNT2B17q/EnjZzBYT+IbN9GrrbCAwquTHBLpzvor2P0QkSKMtiogkCLXQRUQShAJdRCRBKNBFRBKEAl1EJEEo0EVEEoQCXUQkQSjQRUQSxP8ByjO06YQU0BMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds,tpr, thresholds,fpr)\n",
    "plt.legend(['TPR','FPR'])\n",
    "plt.xlabel('Threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC=0.991149\n"
     ]
    }
   ],
   "source": [
    "# AUC \n",
    "auc=metrics.roc_auc_score(Y_test, yprob[:,1])\n",
    "print(\"AUC=%f\" % auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the weight vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a stem plot of the coefficients, `W` in the logistic regression model.  You can get the coefficients from `logreg.coef_`, but you will need to reshape this to a 1D array.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StemContainer object of 3 artists>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "W = logreg.coef_.reshape(len(logreg.coef_[0]),)\n",
    "plt.stem(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that `W[i]` is very large for a few components `i`.  These are the genes that are likely to be most involved in Down's Syndrome.  \n",
    "\n",
    "Find the names of the genes for two components `i` where the magnitude of `W[i]` is largest.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Predictor: ITSN1_N\n",
      "Second Predictor: APP_N\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "genes=df_4.keys()\n",
    "\n",
    "top_2_gene = genes[np.argsort(W)[-2:]]\n",
    "print(f\"Top Predictor: {top_2_gene[-1]}\")\n",
    "print(f\"Second Predictor: {top_2_gene[-2]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "The above meaured the accuracy on the training data.  It is more accurate to measure the accuracy on the test data.  Perform 10-fold cross validation and measure the average precision, recall and f1-score, as well as the AUC.  Note, that in performing the cross-validation, you will want to randomly permute the test and training sets using the `shuffle` option.  In this data set, all the samples from each class are bunched together, so shuffling is essential.  Print the mean precision, recall and f1-score and error rate across all the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9528, SE=0.0109\n",
      "Recall =    0.9618, SE=0.0083\n",
      "f1 =        0.9569, SE=0.0072\n",
      "Accuracy =  0.9602, SE=0.0065\n",
      "AUC =       0.9891, SE=0.0028\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold, shuffle=True)\n",
    "prec = []\n",
    "rec = []\n",
    "f1 = []\n",
    "acc = []\n",
    "auc = []\n",
    "for train, test in kf.split(Xs):            \n",
    "    # Get training and test data\n",
    "    Xtr = Xs[train,:]\n",
    "    ytr = y[train]\n",
    "    Xts = Xs[test,:]\n",
    "    yts = y[test]\n",
    "    \n",
    "    # Fit a model\n",
    "    logreg.fit(Xtr, ytr)\n",
    "    yhat = logreg.predict(Xts)\n",
    "    \n",
    "    # Measure performance\n",
    "    preci,reci,f1i,_= precision_recall_fscore_support(yts,yhat,average='binary') \n",
    "    prec.append(preci)\n",
    "    rec.append(reci)\n",
    "    f1.append(f1i)\n",
    "    acci = np.mean(yhat == yts)\n",
    "    acc.append(acci)\n",
    "    \n",
    "    # do the acu\n",
    "    yprob = logreg.predict_proba(Xts)\n",
    "    auc.append(metrics.roc_auc_score(yts, yprob[:,1]))\n",
    "\n",
    "# Take average values of the metrics\n",
    "precm = np.mean(prec)\n",
    "recm = np.mean(rec)\n",
    "f1m = np.mean(f1)\n",
    "accm= np.mean(acc)\n",
    "aucm= np.mean(auc)\n",
    "\n",
    "# Compute the standard errors\n",
    "prec_se = np.std(prec)/np.sqrt(nfold-1)\n",
    "rec_se = np.std(rec)/np.sqrt(nfold-1)\n",
    "f1_se = np.std(f1)/np.sqrt(nfold-1)\n",
    "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
    "auc_se = np.std(auc)/np.sqrt(nfold-1)\n",
    "\n",
    "print('Precision = {0:.4f}, SE={1:.4f}'.format(precm,prec_se))\n",
    "print('Recall =    {0:.4f}, SE={1:.4f}'.format(recm, rec_se))\n",
    "print('f1 =        {0:.4f}, SE={1:.4f}'.format(f1m, f1_se))\n",
    "print('Accuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))\n",
    "print('AUC =       {0:.4f}, SE={1:.4f}'.format(aucm, auc_se))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification\n",
    "\n",
    "Now use the response variable in `df1['class']`.  This has 8 possible classes.  Use the `np.unique` funtion as before to convert this to a vector `y` with values 0 to 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c-CS-m' 'c-CS-s' 'c-SC-m' 'c-SC-s' 't-CS-m' 't-CS-s' 't-SC-m' 't-SC-s']\n",
      "[0 0 0 ... 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# print(df1['class'])\n",
    "labels, y = np.unique(df1['class'].values, return_inverse=True)\n",
    "print (labels)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a multi-class logistic model by creating a `LogisticRegression` object, `logreg` and then calling the `logreg.fit` method. In general, you could either use the 'one over rest (ovr)' option or the 'multinomial' option. In this exercise use the default 'ovr' and `C=1`. As an optional exercise, you could also compare the results obtained with these two options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1, multi_class='ovr')\n",
    "Xs_train, Xs_test, Y_train, Y_test = model_selection.train_test_split( Xs, y, test_size=0.33)\n",
    "logreg.fit(Xs_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure the accuracy on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right: 0.9831932773109243 vs Wrong: 0.01680672268907568\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "yhat = logreg.predict(Xs_test)\n",
    "acc = np.mean(yhat==Y_test)\n",
    "print(f\"Right: {acc} vs Wrong: {1-acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform 10-fold cross validation, and measure the confusion matrix `C` on the test data in each fold. You can use the `confustion_matrix` method in the `sklearn` package.  Add the confusion matrix counts across all folds and then normalize the rows of the confusion matrix so that they sum to one.  Thus, each element `C[i,j]` will represent the fraction of samples where `yhat==j` given `ytrue==i`.  Print the confusion matrix.  You can use the command\n",
    "\n",
    "    print(np.array_str(C, precision=4, suppress_small=True))\n",
    "    \n",
    "to create a nicely formatted print.  Also print the overall mean and SE of the test accuracy across the folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Normalized Confusion Matrix for Fold: 1\n",
      "[[0.9971 0.     0.     0.     0.0767 0.     0.     0.    ]\n",
      " [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      " [0.0586 0.     0.     0.9966 0.0586 0.     0.     0.    ]\n",
      " [0.     0.0624 0.     0.     0.9981 0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      " [0.     0.     0.1414 0.     0.     0.     0.9899 0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix for Fold: 2\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix for Fold: 3\n",
      "[[0.9959 0.     0.     0.     0.0905 0.     0.     0.    ]\n",
      " [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix for Fold: 4\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix for Fold: 5\n",
      "[[0.9983 0.0587 0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.9966 0.     0.     0.0586 0.0586 0.     0.    ]\n",
      " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix for Fold: 6\n",
      "[[0.9975 0.     0.     0.     0.0712 0.     0.     0.    ]\n",
      " [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      " [0.0995 0.     0.     0.     0.995  0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix for Fold: 7\n",
      "[[0.9978 0.     0.0665 0.     0.     0.     0.     0.    ]\n",
      " [0.083  0.9965 0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     1.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix for Fold: 8\n",
      "[[1.     0.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     1.     0.     0.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.9965 0.     0.     0.     0.     0.083 ]\n",
      " [0.     0.     0.     1.     0.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     1.     0.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     1.     0.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     1.     0.    ]\n",
      " [0.     0.     0.     0.     0.     0.     0.     1.    ]]\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix for Fold: 9\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix for Fold: 10\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      "\n",
      "Accuracy =  0.9602, SE=0.0048\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# TODO\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold, shuffle=True)\n",
    "acc = []\n",
    "\n",
    "fold=1\n",
    "\n",
    "for train, test in kf.split(Xs):\n",
    "    # split\n",
    "    Xtr = Xs[train,:]\n",
    "    ytr = y[train]\n",
    "    Xts = Xs[test,:]\n",
    "    yts = y[test]\n",
    "    \n",
    "    # fit the model\n",
    "    logreg.fit(Xtr, ytr)\n",
    "    yhat = logreg.predict(Xts)\n",
    "    \n",
    "    # accuracy compute    \n",
    "    acci = np.mean(yhat == yts)\n",
    "    acc.append(acci)\n",
    "    \n",
    "    # confusion matrix     \n",
    "    cm_norm = preprocessing.normalize(confusion_matrix(yts, yhat))\n",
    "    print(f\"\\n\\nNormalized Confusion Matrix for Fold: {fold}\")\n",
    "    print(np.array_str(cm_norm, precision=4, suppress_small=True))\n",
    "    fold+=1\n",
    "    \n",
    "accm = np.mean(accm)\n",
    "acc_se = np.std(acc)/np.sqrt(nfold-1)\n",
    "print('\\n\\nAccuracy =  {0:.4f}, SE={1:.4f}'.format(accm, acc_se))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the logistic regression on the entire training data and get the weight coefficients.  This should be a 8 x 77 matrix.  Create a stem plot of the first row of this matrix to see the coefficients on each of the genes for the first class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<StemContainer object of 3 artists>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "logreg.fit(Xs, y)\n",
    "# yhat = logreg.predict(Xts)\n",
    "# TODO\n",
    "\n",
    "W = logreg.coef_\n",
    "plt.stem(W[0,:])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## L1-Regularization\n",
    "\n",
    "# Graduate students only complete this section.\n",
    "\n",
    "In most genetic problems, only a limited number of the tested genes are likely influence any particular attribute.  Hence, we would expect that the weight coefficients in the logistic regression model should be sparse.  That is, they should be zero on any gene that plays no role in the particular attribute of interest.  Genetic analysis commonly imposes sparsity by adding an l1-penalty term.  Read the `sklearn` [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) on the `LogisticRegression` class to see how to set the l1-penalty and the inverse regularization strength, `C`.\n",
    "\n",
    "Using the model selection strategies from the [prostate cancer analysis demo](../unit03_model_sel/demo03_2_prostate.ipynb), use K-fold cross validation to select an appropriate inverse regularization strength.  \n",
    "* Use 10-fold cross validation \n",
    "* You should select around 20 values of `C`.  It is up to you to find a good range.\n",
    "* For each C and each fold, you should compute the classification error rate \n",
    "* For each C and each fold, you should also determine the nubmer of non-zero coefficients for the first class. For this purpse, you can assume coefficient with magnitude <0.01 as zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the mean and standard error on the error rate for each `C` and plot the results (Use `errorbar()` method).  Also determine and print the minimum test error rate and corresponding C value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the minimum error rate is significantly below the classifier that did not use the l1-penalty.  Use the one-standard error rule to determine the optimal `C` and the corresponding test error rate. Note that because `C` is inversely proportional to the regularization strength, you want to select a `C` as *small* as possible while meeting the error target!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# C_opt = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How does the test error rate compare with the classifier that did not use the l1-penalty? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Type Answer Here:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot the nubmer of non-zero coefficients for the first class for different C values. Also determine and print the number of non-zero coefficients corresponding to C_opt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the optimal `C`, fit the model on the entire training data with l1 regularization. Find the resulting weight matrix, `W_l1`.  Plot the first row of this weight matrix and compare it to the first row of the weight matrix without the regularization.  You should see that, with l1-regularization, the weight matrix is much more sparse and hence the roles of particular genes are more clearly visible. Please also compare the accuracy for the training data using optimal `C` with the previous results not using LASSO regularization. Do you expect the accuracy to improve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
